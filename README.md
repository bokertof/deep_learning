# The Toy Deep Learning Projects

1) Word2Vec - one of the possible ways to get words embeddings. Both CBOW and SkipGram approaches are implemented in pure NumPy
2) Pre-trained RoBERTa model (from DeepPavlov, http://deeppavlov.ai/) with CRF-head - solution of punctuation restoration task for the russian language (>90% accuracy)
3) Seq2Seq model with Attention (Bahdanau and Luong) for translation from German into English (BLEu score ~ 26)
4) Simple deep-CNN Autoencoder on the face dataset. Smile vector was computed that can be used to add smiles to images of sad people
